{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char Prediction using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download data of Alice in Wonderland or Dracula from https://www.gutenberg.org/browse/scores/top in plain text format\n",
    "2. Create an char_to_int map which maps each character used in the novel to an integer. example {a: 3}\n",
    "3. Read data from the text file and do the following:\n",
    "    3.1 Create a sliding window in which it takes in first 100 characters as the input sequence and 101th character as the output sequence. (It slides over every character).\n",
    "    For example: \n",
    "        \"Avul Pakir Jainulabdeen Abdul Kalam better known as A.P.J. Abdul Kalam\"\n",
    "        You should slide from \"A\" to the 100th char and 101th char will be your output.\n",
    "        Then you should start sliding from \"v\" to the 100th char and 101th char will be your output.\n",
    "    The input and the output sequence should be converted to their integer representation using the char_to_int map.\n",
    "    With this you basically have two arrays seqIn and seqOut with each element containing integer representation of 100 characters and 1 character respectively.\n",
    "    seqIn = [[10........15], [5.....25]...] seqOut = [5, 2, 5]\n",
    "4. Now reshape your seqIn as (NumberOfSamples, 100, 1) - So you basically get this [[[10]........[15]], [[5]..... [25]]...]\n",
    "5. One hot encode your seqOut using np_utils.to_categorical\n",
    "\n",
    "6. Now create a simple model with LSTM followed by a Dense layer.\n",
    "\n",
    "7. Then, given a seed sentence predict the next character using the model created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "# Sequence to attain Padding\n",
    "from keras.preprocessing import sequence\n",
    "# Importing RNN's LSTM\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "# Applying Sequential algorithm to model\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Original_file = open('AliceInWonderland').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing all '\\n' from the document\n",
    "file = Original_file.replace('\\n', ' ').replace('\\r', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating number of Unique Letters in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stores the unique letters from the document\n",
    "letters = list(set(file))\n",
    "\n",
    "# Stores the number of unique letters which is the num_classes in outputs\n",
    "unique_output_Values = len(letters)\n",
    "unique_output_Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Networks accepts only number inputs, so converting text(letters) into numbers\n",
    "\n",
    "## Maps letters to numbers\n",
    "char_to_int = dict(zip(letters, [i for i in range(len(letters))]))\n",
    "\n",
    "## Maps numbers back to text\n",
    "int_to_char = dict(zip([i for i in range(len(letters))],letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' SLIDING FUNCTION: Slides over the input text file character by character'''\n",
    "\n",
    "def generate_char_Dataset(data, slide):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    ## Generating iput texts(characters)\n",
    "    for index in range(len(data) - slide):\n",
    "        x.append([ch for ch in data[index:index+slide]])\n",
    "        y.append(data[index+slide:index+slide+1])\n",
    "        \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' CHAR TO INT CONVERSION FUNCTION: Converts character dataset to int dataset '''\n",
    "\n",
    "def char_Dataset_to_int_Dataset(x,y, char_to_int):\n",
    "    \n",
    "    input_to_int = []\n",
    "    output_to_int = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        input_to_int.append([char_to_int[char] for char in x[i]])\n",
    "        output_to_int.append([char_to_int[char] for char in y[i]])\n",
    "    \n",
    "    return input_to_int, output_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' (BACK) INT TO CHAR CONVERSION FUNCTION: Accepts output(y) i.e. List of lists '''\n",
    "\n",
    "def int_Dataset_to_char_Dataset(y, int_to_char):\n",
    "    \n",
    "    back_to_char = []\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        back_to_char.append([int_to_char[y[i][0]]])\n",
    "        \n",
    "    return back_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' INTIALIZATION FUNCTION: Accepts tokenized words, slide, list of unique words from the doc '''\n",
    "\n",
    "def initialize(data, slide, char_to_int):\n",
    "    \n",
    "    char_Dataset = generate_char_Dataset(data, slide)\n",
    "    int_Dataset = char_Dataset_to_int_Dataset(char_Dataset[0], char_Dataset[1], char_to_int)\n",
    "    \n",
    "    # INPUT: e.g. [[12,21,34], [12,33,41], ...] - List of Lists\n",
    "    seqInput = int_Dataset[0]\n",
    "    \n",
    "    # OUTPUT: e.g. flatten([[12],[24],[2],[5] ...] - List of Lists = [12,24,2,5....]\n",
    "    seqOutput = list(np.array(int_Dataset[1]).flatten())\n",
    "    \n",
    "    seqInput_RESHAPED = np.array(seqInput).reshape(len(seqInput), slide, 1)\n",
    "    \n",
    "    return seqInput_RESHAPED, seqOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_SET = initialize(file, 100, char_to_int)\n",
    "\n",
    "X = DATA_SET[0]\n",
    "Y = DATA_SET[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163716, 100, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' X=(163716, 100, 1) \n",
    "\n",
    "    Number of samples = 163716\n",
    "    Number of inputs  = 100 (Letter1, Letter2...., Letter100)\n",
    "               Output = 1 (Letter101th)\n",
    "'''\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words = 20000\n",
    "\n",
    "## Dividing the whole No. of samples into batches of 32\n",
    "batch_size = 32\n",
    "\n",
    "## Number of iterations\n",
    "epochs = 2\n",
    "\n",
    "## Number of Output classes\n",
    "num_classes = unique_output_Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163716 163716\n"
     ]
    }
   ],
   "source": [
    "print(len(X),len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.01, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding Output Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Total no. of classes = Unique Values in the document, [0,0,0,.....1]\n",
    "y_train_oneHotEncoded = keras.utils.to_categorical(y_train, num_classes=unique_output_Values)\n",
    "y_test_oneHotEncoded = keras.utils.to_categorical(y_test, num_classes=unique_output_Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162078 1638\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train_oneHotEncoded), len(y_test_oneHotEncoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162078, 100, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1638, 85)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_oneHotEncoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 162078 samples, validate on 1638 samples\n",
      "Epoch 1/1\n",
      " 45120/162078 [=======>......................] - ETA: 1790s - loss: 3.1302 - acc: 0.1949"
     ]
    }
   ],
   "source": [
    "# Model Architecture:  Consists of 2 LSTM Layers and a Output Dense Layer\n",
    "\n",
    "#       t0 - t1 - t2 - t3 ------ t99    = Sample 1                \n",
    "#       t0 - t1 - t2 - t3 ------ t99    = Sample 2\n",
    "#                                         ...\n",
    "#       t0 - t1 - t2 - t3 ------ t99    = Sample 162078 \n",
    "\n",
    "\n",
    "## Sequential one by one\n",
    "model = Sequential()\n",
    "\n",
    "## LSTM Layer 1: Consists of 256 Neurons. To connect with the second layer of LSTM, return_sequences = True\n",
    "model.add(LSTM(64, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "## LSTM Layer 2: Consists of 256 Neurons in one RNN Layer \n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(unique_output_Values, activation=\"sigmoid\"))\n",
    "\n",
    "## Compiling Model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "## Fitting Model without weights(Wr or Wht-1)\n",
    "model.fit(x_train, y_train_oneHotEncoded, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test_oneHotEncoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model.load_weights('weights-improvement-49-1.2575.hdf5', by_name=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.add(Dropout(32, input_shape=(x_train.shape[1], x_train.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate = model.evaluate(x_test, y_test_oneHotEncoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate[1]\n",
    "accuracy*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input = \"Project Gutenberg’s Alice’s Adventures in Wonderland, by Lewis Carroll This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org Title: Alice’s Adventures in Wonderland Author: Lew\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input_seqIn_withChar,test_input_seqOut_withChar = generate_char_Dataset(test_input, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Converting char input sequence to Integer'''\n",
    "test_input_seqIn = []\n",
    "\n",
    "for i in range(len(test_input_seqIn_withChar)):\n",
    "    test_input_seqIn.append([char_to_int[letter] for letter in test_input_seqIn_withChar[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Reshaping seqIn sample'''\n",
    "\n",
    "test_input_seqIn_reshape = np.array(test_input_seqIn).reshape(np.array(test_input_seqIn).shape[0], np.array(test_input_seqIn).shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(test_input_seqIn_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing inputs and outputs in a proper string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = []\n",
    "\n",
    "for i in range(len(test_input_seqIn_withChar)):\n",
    "    input.append(''.join(test_input_seqIn_withChar[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "\n",
    "for i in predictions:\n",
    "    output.append(int_to_char[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''.join(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
